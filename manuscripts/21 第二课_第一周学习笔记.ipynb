{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# course2 week1 笔记\n",
    "---\n",
    "内容概要：\n",
    "* 训练集、验证集、测试集（train、dev、test sets）的意义以及如何划分\n",
    "* 偏差和方差（bias and variance）的区别，如何处理高偏差、高方差以及两者共存的问题\n",
    "* 在神经网络中应用正则化方法降低过拟合风险，如：L2正则化、dropout\n",
    "* 一些加速神经网络训练的方法，如：Normalizing inputs\n",
    "* 梯度校验（Gradient Checking）— 一种网络不起作用时的debug方法\n",
    "\n",
    "\n",
    "\n",
    "* 正则化（Regularization）\n",
    "    \n",
    "    How does regularization prevent overfitting?\n",
    "    dropout\n",
    "    data augmentation\n",
    "    early stopping\n",
    "    \n",
    "* Gradient Checking\n",
    "* Vanishing/exploding gradients\n",
    "* Normalizing inputs\n",
    "\n",
    "\n",
    "正则化 L1范数、L2范数\n",
    "Logistic Regression中的正则化\n",
    "神经网络中的正则化\n",
    "\n",
    "为什么正则化可以降低过拟合的风险？\n",
    "> L2正则能够降低部分神经元的权重，从而事实上简化了网络。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程作业中的知识点\n",
    "---\n",
    "第一份作业：\n",
    "参数初始化方法对神经网络的影响\n",
    "\n",
    "第二份作业：\n",
    "正则化方法降低过拟合风险\n",
    "\n",
    "第三份作业：\n",
    "梯度校验 — 网络不起作用时的debug方法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropout（随机失活）\n",
    "---\n",
    "随机选择一些神经元，删掉，得到简化的神经网络。\n",
    "\n",
    "不能依赖任何特征，因为任何特征都有可能被清除。\n",
    "\n",
    "在计算机视觉中常用，防止过拟合。\n",
    "\n",
    "Why does drop-out work?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他正则化方法\n",
    "---\n",
    "数据增强（data augmentation）-- 图像旋转、缩减\n",
    "\n",
    "early stopping\n",
    "提前停止迭代，决策依据是训练集误差曲线和测试集误差曲线。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Training Data\n",
    "---\n",
    "subtract mean\n",
    "normalize variou\n",
    "\n",
    "意义：让训练更快，不容易错过最优值。\n",
    "\n",
    "\n",
    "### Vanishing / Exploding Gradients 梯度消失，梯度爆炸\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight initialization for deep networks\n",
    "---\n",
    "\n",
    "### 梯度的数值逼近\n",
    "---\n",
    "\n",
    "### 梯度检验 Gradient Checking -- debug神经网络的有效方法\n",
    "---\n",
    "1、不要再训练过程中进行梯度检验，仅仅在debug过程中使用\n",
    "2、\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## \n",
    "\n",
    "[关于梯度消失，梯度爆炸的问题](http://blog.csdn.net/qq_29133371/article/details/51867856)\n",
    "[梯度爆炸和梯度消失的本质原因](http://blog.csdn.net/lujiandong1/article/details/53320174)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
